\section{\centering Элементы машинного обучения} 
Здесь будут приведены некоторые теоретические сведения из анализа данных и машинного обучения. За более подробным материалом можно обратиться к \cite{bishop, mathforml, ml-coursera}.

\subsection{\centering Введение в машинное обучение}
{\it Машинное обучение} -- раздел, стоящий на пересечении математики и компьютерных наук, который, главным образом, решает задачу восстановления некоторой зависимости, используя некоторые данные, которые представляют такую зависимость. 

Машинное обучение можно разделить на категории: например, очень популярное разделение -- это разделение по типу обучения:
\begin{itemize}
	\item обучение с учителем(Supervised Learning);
	\item обучение без учителя(Unsupervised Learning);
	\item обучение с подкреплением(Reinforcement Learning).
\end{itemize}

Остановимся более подробно на обучении с учителем. Данный вид машинного обучения предполагает, что имеется некоторая выборка $X$ -- {\it множество объектов}, некоторая выборка $Y$ -- {\it множество ответов}, и необходимо восстановить {\it скрытую зависимость} $y: X \to Y$. Как правило, саму зависимость восстановить порой очень трудно, поэтому достаточно найти такой алгоритм $a: X \to Y$, который приближает $y$ на $X$. При этом сами объекты задаются через {\it признаки} $f: X \to D$, где $D$ -- {\it пространство признаков}. Признаки -- это какие-либо характеристики, которые описывают данный объект. 

Основные задачи обучения с учителем:
\begin{itemize}
	\item регрессия;
	\item классификация.
\end{itemize}
Фундаментальная разница между этими двумя типами задач следующая: задача {\it регрессии} -- восстановление непрерывной функции, которая характеризует скрытую зависимость между входными переменными и выходными. Регрессия таким имеет возможность предсказывать численное значение этой скрытой непрерывной функции по новым значениям входных переменных. Задача {\it классификации} же в том, чтобы восстановить зависимость между входными параметрами, описывающие объект, и тем, к какому классу данный объект принадлежит. То есть в случае задачи классификации скрытая зависимость описывается некоторой пороговой функцией, где каждое значение области значения соответствует некоторому классу.

Важным шагом в решении задачи как регрессии, так и классификации, является выбор модели и настройка ее параметров. {\it Модель} -- это параметрическое семейство функций 
\[
	A \coloneqq \{ a(x) = g(x, \theta) | \theta \in \Theta \},
\]
где $\Theta$ -- множество значений параметра $\theta$, а $g: X \times \Theta \to Y$ -- некоторая фиксированная функция.

Решение задачи машинного обучения разделяется на два этапа:
\begin{enumerate}
	\item этап обучения;
	\item этап применения.
\end{enumerate}

Этап обучения представляет из себя построение алгоритма выбора подходящей модели, т.е. имеется отображение $\mu: X \times Y \to A$, которое по каждой выборке $(X,Y)$, которую обычно называют {\it обучающей выборкой}, ставит в соответствие алгоритм $a \coloneqq \mu(X, Y)$, который наилучшим образом описывает скрытую зависимость $y: X \to Y$. Для выбора модели необходимо сравнивать точность, которую они демонстрируют. Для этого обычно вводят т.н. {\it функцию потерь (loss function)} $L(a,x)$, которая измеряет величину ошибки алгоритма $a \in A$ на объекте $x \in X$. Например, для задачи классификации рассматривают {\it индикатор ошибки (Accuracy)}:
\[
	L(a,y,x) = [a(x) \neq y(x)].
\]

Для задач регрессии в качестве функции потерь рассматривают {\it квадратичную ошибку} 
\[
	L(a,y,x) = (a(x) - y(x))^2
\]
или {\it абсолютное значение ошибки}
\[
	L(a,y,x) = \abs{a(x) - y(x)}.
\]

Чтобы оценить качество работы алгоритма $a$ на всей выборке $X$ обычно считают среднее арифметическое по значениям функции потерь для каждого объекта $x \in X$(иногда его называют {\it эмпирическим риском}):
\[
	Q(a,X, Y) = \frac{1}{\abs{X}}\sum\limits_{i=1}^{\abs{X}} L(a,y_i, x_i).
\]
И тогда для выбора модели решают задачу минимизации эмпирического риска:
\[
	\mu(X, Y) = \arg\min\limits_{a \in A} Q(a, X, Y).
\]


Этап применения -- это следующий этап, который представляет собой т.н. задачу вывода. На этом этапе выбранный алгоритм $a$ для новых объектов $X^*$, которые не были задействованы в этапе обучения, выдает ответы $a(X^*)$. Обычно такую выборку $X^*$ называют {\it тестовой выборкой}. Одна из основных проблем, которая возникает на данном этапе -- это проблема {\it переобучения}. Переобучение -- это ситуация, которая возникает в следствие допущенной ошибки в ходе этапа обучения, и характеризуется тем, что величина ошибки на тестовой выборке сильно превышает величину ошибки на обучающей:
\[
	Q(\mu(X, Y), X^*, Y^*) >> Q(\mu(X, Y), X, Y).
\]
Зачастую такую проблему можно исправить, если правильно подобрать параметры модели, которая использовалась для обучения.

Так как данная работа представляет собой решение задачи классификации, то остановимся поподробнее на соответствующих моделях машинного обучения.

\subsection{\centering Логистическая регрессия}
Логистическая регрессия -- один из самых простых и популярных алгоритмов для задачи классификации. Смысл данного метода заключается в том, чтобы построить разделяющую гиперплоскость в пространстве признаков, позволяющую отделить классы друг от друга. 

В логистической регрессии строится линейный алгоритм классификации $ a:X \to Y $, где $X$ -- пространство признаков, а $Y$ -- конечное множество номеров классов. Алгоритм имеет вид:
\[
a(x,w) = sign(\sum_{j=1}^{n}w_jf_j(x)-w_0) = sign\langle x,w\rangle,
\]
где $w$ -- вектор весов, $w_0$ -- порог принятия решения, а $ \langle \cdot, \cdot \rangle $ -- скалярное произведение.

Задача обучения линейного классификатора заключается в том, чтобы по выборке настроить вектор весов. Для этого в логистической регрессии решается задача минимизации эмпирического риска с специальной функцией потерь вида:
\[
Q(w) = \sum_{i=1}^{m}ln(1+e^{-y_i\langle x_i,w\rangle}) \to \min_{w}
\]
После нахождения решения $w$, становится возможным не только вычислять классификацию для произвольного объекта, но и оценивать апостериорные вероятности его принадлежности классам:
\[
\mathbb{P}(y|x) = \sigma(y\langle x,w\rangle)
\]
где $\sigma(z) = \frac{1}{1+e^{-z}}$ -- сигмоидная функция.


\subsection{\centering Метод опорных векторов}
Метод опорных векторов -- также очень популярный метод машинного обучения, достаточно мощный и многогранный, применяемый в задачах классификации и регрессии. 

Фундаментальная идея метода опорных векторов заключается в поиске гиперплоскости с наилучшим отступом -- расстоянием между гиперплоскостью и опорными векторами -- векторами, которые ближе всего находятся к разделяющей гиперплоскости. 

Ищется решение задачи регрессии в линейном случае: 
\[
f(x) = \langle w,x\rangle - w_0.
\] 
Функция потерь принимает вид:
\[
a(x_i) = \abs{\langle w,x_i\rangle - w_0 - y_i}_{\varepsilon} 
\]
для каждого вектора $(x_i,y_i)$.

В таком случае функционал потерь принимает вид:
\[
Q_\varepsilon(a,X) = \sum_{i=1}^{l}\abs{\langle w,x_i\rangle - w_0-y_i}_\varepsilon + \tau\langle w,w\rangle^2 \to \min_{w,w_0}.
\]
Последнее слагаемое удерживает коэффициенты $w$ от бесконечного возрастания. Аналогично задаче классификации, решение зависит от скалярного произведения объектов, а не от самих объектов. Минимизация в данном случае эквивалентна задаче квадратичного программирования с ограничениями типа неравенств. 

\subsection{\centering Случайный лес}
Случайный лес -- это алгоритм машинного обучения, заключающийся в использовании нескольких решающих деревьев. На самом деле, случайный лес -- это частный случай бустинга.

Беггинг (bootstrap aggregation) -- это метод композиции базовых классификаторов $b_t$, которые обучаются независимо по случайной выборке длины $l$ с повторениями. Обычно предполагается, что базовые классификаторы хотя бы несколько лучше случайного угадывания и различны между собой. Тогда из данных базовых классификаторов получают один агрегированный, который работает лучше. В случае случайного леса базовые классификаторы -- это решающие деревья без усечения(прунинга). Помимо генерирования подвыборки для обучения, генерируют случайное подмножество $F_t \subseteq F$ признаков, на которых обучают базовые классификаторы. Т.е., таким образом, если $\mu(F_t, U_t)$ -- метод обучения алгоритма по подвыборке $U_t \subseteq X$ на $F_t \subseteq F$ признаках, то $b_t \coloneqq \mu(F_t, U_t)$.

Для подбора числа деревьев $T$ применяют критерий {\it out-of-bag}:
\[
	\mathrm{out\text{-}of\text{-}bag}(a) = \sum\limits_{i=1}^l\big[ \mathrm{sgn}\big(\sum\limits_{t=1}^T [x_i \notin U_t]b_t(x_i) \big) \neq y_i \big] \to \min.
\]

Т.е. при таком критерии подсчитывается число ошибок полученного классификатора на объектах обучающей выборки $x_i$, при этом не учитываются голоса тех деревьев, которые непосредственно обучались на объекте $x_i$. Такой критерий  является несмещенной оценкой обобщающей способности.

\subsection{\centering Градиентный бустинг}
Градиентный бустинг — это метод машинного обучения, который, как и случайный лес, использует несколько базовых классификаторов. В случае градиентного бустинга используется {\it линейная комбинация} $b$ базовых алгоритмов $b_t$:
\[
	b(x) = C\big(\sum\limits_{t=1}^T \alpha_t b_t(x)\big),
\]
где $C: \mathbb{R} \to Y$ -- решающее правило, $a_t \geq 0$. Например, в задачах регрессии $C = id$, а в задачах бинарной классификации $C = sgn$.

Далее происходит оптимизация функционала качества $Q(\alpha, b)$ с некоторой функцией потерь $L(b,y)$
\[
	Q(\alpha, b) = \sum_{i=1}^lL\big(\sum_{t=1}^{T-1} \alpha_t b_t(x_i) + \alpha b(x_i), y_i\big) \to \min\limits_{\alpha, b}.
\]
Если $u_{T-1} \coloneqq \sum\limits_{t=1}^{T-1} \alpha_t b_t(x) = (u_{T-1, i})$, а $u_{T} \coloneqq \sum\limits_{t=1}^{T-1} \alpha_t b_t(x) + \alpha b(x_i) = (u_{T, i})$. Тогда функционал имеет вид:
\[
	Q(\alpha, b) = \sum_{i=1}^l L(u_{T, i}, y_i) \to \min\limits_{\alpha, b}.
\]

Такую задачу оптимизации можно решить градиентным спуском: 
\[{u_T \coloneqq u_{T-1} - \alpha g,}\] 
где ${g = L^{'}(u_{T-1}, y)}$. Это можно истолковать как добавление нового базового алгоритма $b_t$. Так как в общем случае $b_t \neq g$, то ищется такой $b_t$, чтобы вектор $b_t(x)$ приближал антиградиент $-g$:
\[
	b_t \coloneqq \arg \min\limits_{b} \sum_{i=1}^l (b(x_i) - g_i)^2.
\]
Это происходит до тех пор, пока значения функционала не сойдутся, либо пока не выполнится одно из правил ранней остановки.
\iffalse
Градиентный бустинг — это метод машинного обучения, посвященный решению для задач классификации и регрессии, которая строит модель предсказания в форме ансамбля слабых предсказывающих моделей, обычно деревьев решений. Обучение
ансамбля проводится последовательно в отличие, например от бэггинга. На
каждой итерации вычисляются отклонения предсказаний уже обученного ансамбля на обучающей выборке. Следующая модель, которая будет добавлена в ансамбль будет предсказывать эти отклонения. Таким образом, добавив
предсказания нового дерева к предсказаниям обученного ансамбля мы можем
уменьшить среднее отклонение модели, которое является таргетом оптимизационной задачи. Новые деревья добавляются в ансамбль до тех пор, пока ошибка
уменьшается, либо пока не выполняется одно из правил ранней остановки.
\fi